# Vision-Language Models in Remote Sensing: Current Progress and Future Trends

视觉语言模型适合需要视觉和文本理解的任务，例如图像描述、视觉问题回答。本文总结了视觉基础模型VLM在遥感场景上的进展、挑战、以及未来的发展，

## FROM VISION-CENTRIC TO VISION-LANGUAGE MODELS

Vision-Centric Models

包含CNN、Transformer的有监督网络结构；

Large Language Models（LLM）

GPT、BERT等；

Vision-Language Models

包含Fusion encoder、Dual encoder两类；CLIP就属于第二类；

## VISION-LANGUAGE MODELS IN REMOTE SENSING

* Vision-Centric Foundation Models

在大量数据上训练基础模型；

* Image Captioning

RSGPT；

* Text-based Image Generation

最初以GAN为主，现在的通过文本生成图片好像还很少，更别提生成变化检测样本了；

* Text-based Image Retrieval

TextRS数据集；

* Visual Question Answering（VQA）

* Visual Grounding

* Zero-Shot Scene Classification

* Few-Shot Object Detection

* Few-/Zero-shot Semantic Segmentation

## CONCLUSION AND FUTURE TRENDS

* Large-scale image-text pair dataset

大量的图像文本对数据集；

* Unified vision-language models

统一的视觉语言模型；

* Text-based image generation using diffusion models

基于文本的扩散图像生成；

* Few-/zero-shot learning

少样本、零样本学习；

* Efficient finetuning on RS data

在遥感数据上的微调

* Integrate RS expert knowledge into LLMs

集成遥感先验知识；

* Linking text-based information with RS via geolocation

将文本知识与遥感的地域位置联系；

* Climate Change Adaptation and Mitigation

气候变化适应；
