# 提示原则

## 原则一：编写清晰、具体的指令

使用分隔符清晰地表示输入的不同部分。将不同的指令、上下文、输入隔开，避免意外的混淆。你可以选择用 ```，"""，< >，$<tag> </tag>$，: 等做分隔符，只要能明确起到隔断作用即可。

使用分隔符尤其重要的是可以防止 提示词注入（Prompt Injection）。什么是提示词注入？就是用户输入的文本可能包含与你的预设 Prompt 相冲突的内容，如果不加分隔，这些输入就可能“注入”并操纵语言模型，导致模型产生毫无关联的乱七八糟的输出。

```python
    text = f"""
    您应该提供尽可能清晰、具体的指示，以表达您希望模型执行的任务。\
    这将引导模型朝向所需的输出，并降低收到无关或不正确响应的可能性。\
    不要将写清晰的提示词与写简短的提示词混淆。\
    在许多情况下，更长的提示词可以为模型提供更多的清晰度和上下文信息，从而导致更详细和相关的输出。
    """
    # 需要总结的文本内容
    prompt = f"""
    把用三个反引号括起来的文本总结成一句话。
    ```{text}```
    """
    # 指令内容，使用 ``` 来分隔指令和待总结的内容
    response = get_completion(prompt)
```

寻求结构化的输出。按照某种格式组织的内容，例如JSON、HTML等。这种输出非常适合在代码中进一步解析和处理。例如，您可以在 Python 中将其读入字典或列表中。

```python
    prompt = f"""
    请生成包括书名、作者和类别的三本虚构的、非真实存在的中文书籍清单，\
    并以 JSON 格式提供，其中包含以下键:book_id、title、author、genre。
    """
    response = get_completion(prompt)
    print(type(response))  # str
```

要求模型检查是否满足条件

如果任务包含不一定能满足的假设（条件），我们可以告诉模型先检查这些假设，如果不满足，则会指出并停止执行后续的完整流程。您还可以考虑可能出现的边缘情况及模型的应对，以避免意外的结果或错误发生。

```python
    text_2 = f"""
    今天阳光明媚，鸟儿在歌唱。\
    这是一个去公园散步的美好日子。\
    鲜花盛开，树枝在微风中轻轻摇曳。\
    人们外出享受着这美好的天气，有些人在野餐，有些人在玩游戏或者在草地上放松。\
    这是一个完美的日子，可以在户外度过并欣赏大自然的美景。
    """
    prompt = f"""
    您将获得由三个引号括起来的文本。\
    如果它包含一系列的指令，则需要按照以下格式重新编写这些指令：

    第一步 - ...
    第二步 - …
    …
    第N步 - …

    如果文本中不包含一系列的指令，则直接写“未提供步骤”。"
    \"\"\"{text_2}\"\"\"
    """
    response = get_completion(prompt)
    print("Text 2 的总结:")
    print(response)
```

提供少量样例

"Few-shot" prompting，即在要求模型执行实际任务之前，给模型一两个已完成的样例，让模型了解我们的要求和期望的输出样式。

## 原则二：给模型时间去思考

通过 Prompt 指引语言模型进行深入思考。可以要求其先列出对问题的各种看法，说明推理依据，然后再得出最终结论。在 Prompt 中添加逐步推理的要求，能让语言模型投入更多时间逻辑思维，输出结果也将更可靠准确。

综上所述，给予语言模型充足的推理时间，是 Prompt Engineering 中一个非常重要的设计原则。这将大大提高语言模型处理复杂问题的效果，也是构建高质量 Prompt 的关键之处。开发者应注意给模型留出思考空间，以发挥语言模型的最大潜力。

指定完成任务所需的步骤。给定一个复杂任务，给出完成该任务的一系列步骤。

在设计 Prompt 时，我们还可以通过明确指导语言模型进行自主思考，来获得更好的效果。

## 局限性

虚假知识：模型偶尔会生成一些看似真实实则编造的知识

在开发与应用语言模型时，需要注意它们可能生成虚假信息的风险。尽管模型经过大规模预训练，掌握了丰富知识，但它实际上并没有完全记住所见的信息，难以准确判断自己的知识边界，可能做出错误推断。若让语言模型描述一个不存在的产品,它可能会自行构造出似是而非的细节。这被称为“幻觉”(Hallucination)，是语言模型的一大缺陷。
