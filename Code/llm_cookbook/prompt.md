# 面向开发者的提示工程

## 提示原则

### 原则一：编写清晰、具体的指令

使用分隔符清晰地表示输入的不同部分。将不同的指令、上下文、输入隔开，避免意外的混淆。你可以选择用 ```，"""，< >，$<tag> </tag>$，: 等做分隔符，只要能明确起到隔断作用即可。

使用分隔符尤其重要的是可以防止 提示词注入（Prompt Injection）。什么是提示词注入？就是用户输入的文本可能包含与你的预设 Prompt 相冲突的内容，如果不加分隔，这些输入就可能“注入”并操纵语言模型，导致模型产生毫无关联的乱七八糟的输出。

```python
    text = f"""
    您应该提供尽可能清晰、具体的指示，以表达您希望模型执行的任务。\
    这将引导模型朝向所需的输出，并降低收到无关或不正确响应的可能性。\
    不要将写清晰的提示词与写简短的提示词混淆。\
    在许多情况下，更长的提示词可以为模型提供更多的清晰度和上下文信息，从而导致更详细和相关的输出。
    """
    # 需要总结的文本内容
    prompt = f"""
    把用三个反引号括起来的文本总结成一句话。
    ```{text}```
    """
    # 指令内容，使用 ``` 来分隔指令和待总结的内容
    response = get_completion(prompt)
```

寻求结构化的输出。按照某种格式组织的内容，例如JSON、HTML等。这种输出非常适合在代码中进一步解析和处理。例如，您可以在 Python 中将其读入字典或列表中。

```python
    prompt = f"""
    请生成包括书名、作者和类别的三本虚构的、非真实存在的中文书籍清单，\
    并以 JSON 格式提供，其中包含以下键:book_id、title、author、genre。
    """
    response = get_completion(prompt)
    print(type(response))  # str
```

要求模型检查是否满足条件

如果任务包含不一定能满足的假设（条件），我们可以告诉模型先检查这些假设，如果不满足，则会指出并停止执行后续的完整流程。您还可以考虑可能出现的边缘情况及模型的应对，以避免意外的结果或错误发生。

```python
    text_2 = f"""
    今天阳光明媚，鸟儿在歌唱。\
    这是一个去公园散步的美好日子。\
    鲜花盛开，树枝在微风中轻轻摇曳。\
    人们外出享受着这美好的天气，有些人在野餐，有些人在玩游戏或者在草地上放松。\
    这是一个完美的日子，可以在户外度过并欣赏大自然的美景。
    """
    prompt = f"""
    您将获得由三个引号括起来的文本。\
    如果它包含一系列的指令，则需要按照以下格式重新编写这些指令：

    第一步 - ...
    第二步 - …
    …
    第N步 - …

    如果文本中不包含一系列的指令，则直接写“未提供步骤”。"
    \"\"\"{text_2}\"\"\"
    """
    response = get_completion(prompt)
    print("Text 2 的总结:")
    print(response)
```

提供少量样例

"Few-shot" prompting，即在要求模型执行实际任务之前，给模型一两个已完成的样例，让模型了解我们的要求和期望的输出样式。

### 原则二：给模型时间去思考

通过 Prompt 指引语言模型进行深入思考。可以要求其先列出对问题的各种看法，说明推理依据，然后再得出最终结论。在 Prompt 中添加逐步推理的要求，能让语言模型投入更多时间逻辑思维，输出结果也将更可靠准确。

综上所述，给予语言模型充足的推理时间，是 Prompt Engineering 中一个非常重要的设计原则。这将大大提高语言模型处理复杂问题的效果，也是构建高质量 Prompt 的关键之处。开发者应注意给模型留出思考空间，以发挥语言模型的最大潜力。

指定完成任务所需的步骤。给定一个复杂任务，给出完成该任务的一系列步骤。

在设计 Prompt 时，我们还可以通过明确指导语言模型进行自主思考，来获得更好的效果。

### 局限性

虚假知识：模型偶尔会生成一些看似真实实则编造的知识

在开发与应用语言模型时，需要注意它们可能生成虚假信息的风险。尽管模型经过大规模预训练，掌握了丰富知识，但它实际上并没有完全记住所见的信息，难以准确判断自己的知识边界，可能做出错误推断。若让语言模型描述一个不存在的产品,它可能会自行构造出似是而非的细节。这被称为“幻觉”(Hallucination)，是语言模型的一大缺陷。

## 迭代优化

在开发大语言模型应用时，采用迭代方式不断优化 Prompt 的过程。作为 Prompt 工程师，关键不是一开始就要求完美的 Prompt，而是掌握有效的 Prompt 开发流程。

具体来说，首先编写初版 Prompt，然后通过多轮调整逐步改进，直到生成了满意的结果。对于更复杂的应用，可以在多个样本上进行迭代训练，评估 Prompt 的平均表现。在应用较为成熟后，才需要采用在多个样本集上评估 Prompt 性能的方式来进行细致优化。因为这需要较高的计算资源。

总之，Prompt 工程师的核心是掌握 Prompt 的迭代开发和优化技巧，而非一开始就要求100%完美。通过不断调整试错，最终找到可靠适用的 Prompt 形式才是设计 Prompt 的正确方法。

## 文本概括

将复杂的文本信息简化，提炼出关键的观点。

## 推断

从各种产品评论和新闻文章中提取出关键的情感和主题。

## 文本转换

大语言模型具有强大的文本转换能力，可以实现多语言翻译、拼写纠正、语法调整、格式转换等不同类型的文本转换任务。利用语言模型进行各类转换是它的典型应用之一。

## 文本扩展

文本扩展是大语言模型的一个重要应用方向，它可以输入简短文本，生成更加丰富的长文。这为创作提供了强大支持，但也可能被滥用。因此开发者在使用时，必须谨记社会责任，避免生成有害内容。

大语言模型中的 “温度”(temperature) 参数可以控制生成文本的随机性和多样性。temperature 的值越大，语言模型输出的多样性越大；temperature 的值越小，输出越倾向高概率的文本。

## 聊天机器人

像 ChatGPT 这样的聊天模型实际上是组装成以一系列消息作为输入，并返回一个模型生成的消息作为输出的。这种聊天格式原本的设计目标是简便多轮对话，它对于不会涉及任何对话的单轮任务也同样有用。
