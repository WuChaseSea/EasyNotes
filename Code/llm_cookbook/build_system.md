# 搭建问答系统

## 语言模型，提问范式与Token

### 语言模型

大语言模型（LLM）是通过预测下一个词的监督学习方式进行训练的。具体来说，首先准备一个包含数百亿甚至更多词的大规模文本数据集。然后，可以从这些文本中提取句子或句子片段作为模型输入。模型会根据当前输入 Context 预测下一个词的概率分布。通过不断比较模型预测和实际的下一个词，并更新模型参数最小化两者差异,语言模型逐步掌握了语言的规律，学会了预测下一个词。

大型语言模型主要可以分为两类:基础语言模型和指令调优语言模型。

基础语言模型（Base LLM）通过反复预测下一个词来训练的方式进行训练，没有明确的目标导向。因此，如果给它一个开放式的 prompt ，它可能会通过自由联想生成戏剧化的内容。而对于具体的问题，基础语言模型也可能给出与问题无关的回答。

指令微调的语言模型（Instruction Tuned LLM）则进行了专门的训练，以便更好地理解问题并给出符合指令的回答。指令微调使语言模型更加适合任务导向的对话应用。它可以生成遵循指令的语义准确的回复，而非自由联想。

将基础语言模型转变为指令微调语言模型，首先，在大规模文本数据集上进行无监督预训练，获得基础语言模型。 这一步需要使用数千亿词甚至更多的数据，在大型超级计算系统上可能需要数月时间。 之后，使用包含指令及对应回复示例的小数据集对基础模型进行有监督 fine-tune，这让模型逐步学会遵循指令生成输出，可以通过雇佣承包商构造适合的训练示例。 接下来，为了提高语言模型输出的质量，常见的方法是让人类对许多不同输出进行评级，例如是否有用、是否真实、是否无害等。 然后，您可以进一步调整语言模型，增加生成高评级输出的概率。这通常使用基于人类反馈的强化学习（RLHF）技术来实现。 相较于训练基础语言模型可能需要数月的时间，从基础语言模型到指令微调语言模型的转变过程可能只需要数天时间，使用较小规模的数据集和计算资源。

## Token

LLM 实际上并不是重复预测下一个单词，而是重复预测下一个 token 。对于一个句子，语言模型会先使用分词器将其拆分为一个个 token ，而不是原始的单词。对于生僻词，可能会拆分为多个 token 。这样可以大幅降低字典规模，提高模型训练和推断的效率。例如，对于 "Learning new things is fun!" 这句话，每个单词都被转换为一个 token ，而对于较少使用的单词，如 "Prompting as powerful developer tool"，单词 "prompting" 会被拆分为三个 token，即"prom"、"pt"和"ing"。

 对于英文输入，一个 token 一般对应 4 个字符或者四分之三个单词；对于中文输入，一个 token 一般对应一个或半个词。不同模型有不同的 token 限制，需要注意的是，这里的 token 限制是输入的 Prompt 和输出的 completion 的 token 数之和，因此输入的 Prompt 越长，能输出的 completion 的上限就越低。 ChatGPT3.5-turbo 的 token 上限是 4096。

 ![tokens](./figures/tokens.png)

## 评估输入-分类

在处理不同情况下的多个独立指令集的任务时，首先对查询类型进行分类，并以此为基础确定要使用哪些指令，具有诸多优势。这可以通过定义固定类别和硬编码与处理特定类别任务相关的指令来实现。简而言之，就是根据用户的输入，判断该动作输入系统消息里面的哪种类别；

## 检测输入-监督

### 审核

使用 OpenAI 的审核函数接口（Moderation API ）对用户输入的内容进行审核。该接口用于确保用户输入的内容符合 OpenAI 的使用规定，这些规定反映了OpenAI对安全和负责任地使用人工智能科技的承诺。使用审核函数接口可以帮助开发者识别和过滤用户输入。

### Prompt注入

在构建一个使用语言模型的系统时， 提示注入是指用户试图通过提供输入来操控 AI 系统，以覆盖或绕过开发者设定的预期指令或约束条件。例如，如果您正在构建一个客服机器人来回答与产品相关的问题，用户可能会尝试注入一个 Prompt，让机器人帮他们完成家庭作业或生成一篇虚假的新闻文章。Prompt 注入可能导致 AI 系统的不当使用，产生更高的成本，因此对于它们的检测和预防十分重要。

有两种策略：

* 在系统消息中使用分隔符（delimiter）和明确的指令。
* 额外添加提示，询问用户是否尝试进行 Prompt 注入。

## 思维链推理

有时，语言模型需要进行详细的逐步推理才能回答特定问题。如果过于匆忙得出结论，很可能在推理链中出现错误。因此，我们可以通过“思维链推理”（Chain of Thought Reasoning）的策略，在查询中明确要求语言模型先提供一系列相关推理步骤，进行深度思考，然后再给出最终答案，这更接近人类解题的思维过程。

### 思维链提示设计

思维链提示是一种引导语言模型进行逐步推理的 Prompt 设计技巧。它通过在 Prompt 中设置系统消息，要求语言模型在给出最终结论之前，先明确各个推理步骤。

## Prompt链

链式提示它具有以下优点:

分解复杂度，每个 Prompt 仅处理一个具体子任务，避免过于宽泛的要求，提高成功率。这类似于分阶段烹饪，而不是试图一次完成全部。

降低计算成本。过长的 Prompt 使用更多 tokens ，增加成本。拆分 Prompt 可以避免不必要的计算。

更容易测试和调试。可以逐步分析每个环节的性能。

融入外部工具。不同 Prompt 可以调用 API 、数据库等外部资源。

更灵活的工作流程。根据不同情况可以进行不同操作。

综上，链式提示通过将复杂任务进行科学拆分，实现了更高效、可靠的提示设计。它使语言模型集中处理单一子任务，减少认知负荷，同时保留了多步骤任务的能力。

## 检查输出

在任何场景中，无论是自动化流程还是其他环境，我们都必须确保在向用户展示输出之前，对其质量、相关性和安全性进行严格的检查，以保证我们提供的反馈是准确和适用的。运用审查(Moderation) API 来对输出进行评估，通过额外的 Prompt 提升模型在展示输出之前的质量评估。
